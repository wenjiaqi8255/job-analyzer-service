import logging
from datetime import datetime
from typing import Dict, List

import numpy as np
from sentence_transformers import SentenceTransformer

from .config import PipelineConfig
from .schemas import BaselineVectorSet

logger = logging.getLogger(__name__)


class BaselineGenerator:
    """è¯­ä¹‰åŸºçº¿æ„å»ºå™¨"""

    def __init__(self, config: PipelineConfig, classification_model: SentenceTransformer):
        self.config = config
        self.classification_model = classification_model  # ç”¨äºåˆ†ç±»çš„æ¨¡å‹

        # åˆå§‹åŒ–ä¸“é—¨ç”¨äºå‘é‡ç”Ÿæˆçš„æ¨¡å‹
        logger.info("ğŸ”§ åˆå§‹åŒ–å‘é‡ç”Ÿæˆæ¨¡å‹...")
        try:
            self.vector_model = SentenceTransformer('all-MiniLM-L6-v2')
            logger.info("âœ… æˆåŠŸåŠ è½½å‘é‡ç”Ÿæˆæ¨¡å‹: all-MiniLM-L6-v2")
        except Exception as e:
            logger.error(f"âŒ æ— æ³•åŠ è½½å‘é‡ç”Ÿæˆæ¨¡å‹: {e}")
            raise

    def generate_all_baselines(self, role_classifications: Dict, industry_classifications: Dict) -> Dict:
        """ç”Ÿæˆæ‰€æœ‰åŸºçº¿ï¼ˆåˆ†ç¦»è¯­ä¹‰æ•°æ®å’Œå‘é‡æ•°æ®ï¼‰"""
        logger.info("ğŸ—ï¸ å¼€å§‹ç”Ÿæˆè¯­ä¹‰åŸºçº¿...")

        baselines = {
            'global': self._generate_global_baseline(role_classifications, industry_classifications),
            'roles': self._generate_role_baselines(role_classifications),
            'industries': self._generate_industry_baselines(industry_classifications)
        }

        logger.info("âœ… æ‰€æœ‰åŸºçº¿ç”Ÿæˆå®Œæˆ")
        return baselines

    def _generate_global_baseline(self, role_classifications: Dict, industry_classifications: Dict) -> Dict:
        """ç”Ÿæˆå…¨å±€åŸºçº¿"""
        logger.info("ğŸŒ ç”Ÿæˆå…¨å±€åŸºçº¿...")

        all_skills = set()
        for categories in role_classifications.values():
            for skills in categories.values():
                all_skills.update(skills)

        for categories in industry_classifications.values():
            for skills in categories.values():
                all_skills.update(skills)

        all_skills = list(all_skills)

        # ç»Ÿè®¡ä¿¡æ¯
        role_distribution = {role: sum(len(skills) for skills in categories.values())
                             for role, categories in role_classifications.items()}
        industry_distribution = {industry: sum(len(skills) for skills in categories.values())
                                 for industry, categories in industry_classifications.items()}

        # åˆ†ç¦»è¯­ä¹‰æ•°æ®å’Œå‘é‡æ•°æ®
        semantic_data = {
            'total_skills': len(all_skills),
            'skills_list': sorted(all_skills),  # æŠ€èƒ½åˆ—è¡¨ï¼ˆäººç±»å¯è¯»ï¼‰
            'statistics': {
                'role_distribution': role_distribution,
                'industry_distribution': industry_distribution,
                'total_roles': len(role_classifications),
                'total_industries': len(industry_classifications)
            },
            'metadata': {
                'generation_date': datetime.now().isoformat(),
                'classification_model': self.config.classification_model,
                'vector_model': 'all-MiniLM-L6-v2',
                'embedding_dimension': 384  # all-MiniLM-L6-v2 çš„ç»´åº¦
            }
        }

        # ç”Ÿæˆå‘é‡æ•°æ®
        vector_data = self._generate_vectors_for_skills(all_skills)

        return {
            'semantic_data': semantic_data,
            'vector_data': vector_data
        }

    def _generate_role_baselines(self, role_classifications: Dict) -> Dict:
        """ç”Ÿæˆè§’è‰²åŸºçº¿"""
        logger.info("ğŸ‘” ç”Ÿæˆè§’è‰²åŸºçº¿...")

        role_baselines = {}

        for role, categories in role_classifications.items():
            all_role_skills = []
            for skills in categories.values():
                all_role_skills.extend(skills)

            if len(all_role_skills) < self.config.min_skills_for_baseline:
                logger.warning(f"è§’è‰² {role} æŠ€èƒ½æ•°é‡ä¸è¶³ï¼Œè·³è¿‡åŸºçº¿ç”Ÿæˆ")
                continue

            # è¯­ä¹‰æ•°æ®ï¼ˆäººç±»å¯è¯»ï¼‰
            semantic_data = {
                'role_name': role,
                'categories': categories,
                'total_skills': len(all_role_skills),
                'skills_list': sorted(list(set(all_role_skills))),
                'statistics': {
                    'category_distribution': {cat: len(skills) for cat, skills in categories.items() if skills}
                },
                'metadata': {
                    'generation_date': datetime.now().isoformat(),
                    'classification_model': self.config.classification_model,
                    'vector_model': 'all-MiniLM-L6-v2'
                }
            }

            # å‘é‡æ•°æ®
            vector_data = self._generate_vectors_for_skills(list(set(all_role_skills)))

            role_baselines[role] = {
                'semantic_data': semantic_data,
                'vector_data': vector_data
            }

        return role_baselines

    def _generate_industry_baselines(self, industry_classifications: Dict) -> Dict:
        """ç”Ÿæˆè¡Œä¸šåŸºçº¿"""
        logger.info("ğŸ­ ç”Ÿæˆè¡Œä¸šåŸºçº¿...")

        industry_baselines = {}

        for industry, categories in industry_classifications.items():
            all_industry_skills = []
            for skills in categories.values():
                all_industry_skills.extend(skills)

            if len(all_industry_skills) < self.config.min_skills_for_baseline:
                logger.warning(f"è¡Œä¸š {industry} æŠ€èƒ½æ•°é‡ä¸è¶³ï¼Œè·³è¿‡åŸºçº¿ç”Ÿæˆ")
                continue

            # è¯­ä¹‰æ•°æ®ï¼ˆäººç±»å¯è¯»ï¼‰
            semantic_data = {
                'industry_name': industry,
                'categories': categories,
                'total_skills': len(all_industry_skills),
                'skills_list': sorted(list(set(all_industry_skills))),
                'statistics': {
                    'category_distribution': {cat: len(skills) for cat, skills in categories.items() if skills}
                },
                'metadata': {
                    'generation_date': datetime.now().isoformat(),
                    'classification_model': self.config.classification_model,
                    'vector_model': 'all-MiniLM-L6-v2'
                }
            }

            # å‘é‡æ•°æ®
            vector_data = self._generate_vectors_for_skills(list(set(all_industry_skills)))

            industry_baselines[industry] = {
                'semantic_data': semantic_data,
                'vector_data': vector_data
            }

        return industry_baselines

    def _generate_vectors_for_skills(self, skills: List[str]) -> Dict:
        """ä¸ºæŠ€èƒ½åˆ—è¡¨ç”Ÿæˆç¬¦åˆBaselineVectorSet schemaçš„å‘é‡æ•°æ®å­—å…¸"""
        if not skills:
            return {}

        unique_skills = sorted(list(set(skills))) # ä¿è¯é¡ºåºç¨³å®š

        try:
            skill_embeddings = self.vector_model.encode(unique_skills)
            
            # åˆ›å»ºç¬¦åˆBaselineVectorSet schemaçš„å­—å…¸
            vector_set = BaselineVectorSet(
                vectors=[embedding.tolist() for embedding in skill_embeddings],
                skill_map={skill: i for i, skill in enumerate(unique_skills)},
                model='all-MiniLM-L6-v2',
                dimension=384
            )
            
            # Pydanticæ¨¡å‹è½¬ä¸ºå­—å…¸ä»¥ä¾¿JSONåºåˆ—åŒ–
            return vector_set.dict()
            
        except Exception as e:
            logger.error(f"å‘é‡ç”Ÿæˆå¤±è´¥: {e}")
            return {}

    def _generate_vectors_for_role(self, categories: Dict) -> Dict:
        """DEPRECATED: å‘é‡ç”Ÿæˆå·²ç»Ÿä¸€åˆ° _generate_vectors_for_skills"""
        pass

    def _generate_vectors_for_industry(self, categories: Dict) -> Dict:
        """DEPRECATED: å‘é‡ç”Ÿæˆå·²ç»Ÿä¸€åˆ° _generate_vectors_for_skills"""
        pass 