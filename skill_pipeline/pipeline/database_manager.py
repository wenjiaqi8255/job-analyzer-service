import hashlib
import json
import logging
from typing import Dict, Optional

from supabase import Client, create_client

from .config import PipelineConfig

logger = logging.getLogger(__name__)


class DatabaseManager:
    """æ•°æ®åº“æ“ä½œç®¡ç†å™¨ - åˆ†ç¦»è¯­ä¹‰æ•°æ®å’Œå‘é‡æ•°æ®"""

    def __init__(self, config: PipelineConfig):
        self.config = config
        self.supabase = self._init_supabase()

    def _init_supabase(self) -> Optional[Client]:
        """åˆå§‹åŒ–Supabaseå®¢æˆ·ç«¯"""
        if not self.config.supabase_url or not self.config.supabase_key:
            logger.warning("âš ï¸ Supabaseé…ç½®ç¼ºå¤±ï¼Œè·³è¿‡æ•°æ®åº“æ“ä½œ")
            return None

        try:
            client = create_client(self.config.supabase_url, self.config.supabase_key)
            logger.info("âœ… Supabaseå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            return client
        except Exception as e:
            logger.error(f"âŒ Supabaseå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            return None

    def upload_baselines(self, baselines: Dict) -> Dict:
        """ä¸Šä¼ åŸºçº¿æ•°æ®åˆ°æ•°æ®åº“ï¼ˆåˆ†ç¦»å­˜å‚¨ï¼‰"""
        if not self.supabase:
            logger.warning("âš ï¸ æ•°æ®åº“æœªè¿æ¥ï¼Œè·³è¿‡ä¸Šä¼ ")
            return {'status': 'skipped', 'reason': 'no_database_connection'}

        logger.info("ğŸ“¤ å¼€å§‹ä¸Šä¼ åŸºçº¿æ•°æ®åˆ°åˆ†ç¦»çš„è¡¨...")
        results = {}

        # ä¸Šä¼ å…¨å±€åŸºçº¿
        results['global'] = self._upload_baseline_pair(
            'global', 'global', baselines['global']
        )

        # ä¸Šä¼ è§’è‰²åŸºçº¿
        results['roles'] = {}
        for role, baseline_data in baselines['roles'].items():
            results['roles'][role] = self._upload_baseline_pair(
                'role', role, baseline_data
            )

        # ä¸Šä¼ è¡Œä¸šåŸºçº¿
        results['industries'] = {}
        for industry, baseline_data in baselines['industries'].items():
            results['industries'][industry] = self._upload_baseline_pair(
                'industry', industry, baseline_data
            )

        logger.info("âœ… åŸºçº¿æ•°æ®ä¸Šä¼ å®Œæˆ")
        return results

    def _upload_baseline_pair(self, baseline_type: str, name: str, baseline_data: Dict) -> Dict:
        """ä¸Šä¼ åŸºçº¿æ•°æ®å¯¹ï¼ˆè¯­ä¹‰æ•°æ® + å‘é‡æ•°æ®ï¼‰"""
        try:
            semantic_data = baseline_data.get('semantic_data', {})
            vector_data = baseline_data.get('vector_data', {})

            if not semantic_data:
                logger.warning(f"åŸºçº¿ {name} ç¼ºå°‘è¯­ä¹‰æ•°æ®ï¼Œè·³è¿‡ä¸Šä¼ ")
                return {'status': 'error', 'error': 'missing_semantic_data'}

            # 1. é¦–å…ˆä¸Šä¼ è¯­ä¹‰æ•°æ®åˆ° semantic_baselines è¡¨
            semantic_result = self._upload_semantic_baseline(baseline_type, name, semantic_data)

            if semantic_result['status'] != 'uploaded':
                logger.error(f"è¯­ä¹‰æ•°æ®ä¸Šä¼ å¤±è´¥ï¼Œè·³è¿‡å‘é‡æ•°æ®ä¸Šä¼ : {name}")
                return semantic_result

            baseline_id = semantic_result['id']

            # 2. ç„¶åä¸Šä¼ å‘é‡æ•°æ®åˆ° baseline_vectors è¡¨
            if vector_data:
                vector_result = self._upload_vector_data(baseline_id, vector_data)

                return {
                    'status': 'uploaded',
                    'baseline_id': baseline_id,
                    'semantic_upload': semantic_result,
                    'vector_upload': vector_result
                }
            else:
                logger.warning(f"åŸºçº¿ {name} ç¼ºå°‘å‘é‡æ•°æ®")
                return {
                    'status': 'partial',
                    'baseline_id': baseline_id,
                    'semantic_upload': semantic_result,
                    'vector_upload': {'status': 'skipped', 'reason': 'no_vector_data'}
                }

        except Exception as e:
            logger.error(f"ä¸Šä¼ åŸºçº¿å¯¹ {name} å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}

    def _upload_semantic_baseline(self, baseline_type: str, name: str, semantic_data: Dict) -> Dict:
        """ä¸Šä¼ è¯­ä¹‰æ•°æ®åˆ° semantic_baselines è¡¨"""
        source_hash = self._calculate_hash(semantic_data)

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„è¯­ä¹‰æ•°æ®
        try:
            result = self.supabase.table("semantic_baselines") \
                .select("*") \
                .eq("source_hash", source_hash) \
                .execute()

            if result.data:
                logger.info(f"è¯­ä¹‰åŸºçº¿ {name} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸Šä¼ ")
                return {'status': 'exists', 'id': result.data[0]['id']}
        except Exception as e:
            logger.error(f"æ£€æŸ¥è¯­ä¹‰åŸºçº¿ {name} æ—¶å‡ºé”™: {e}")
            return {'status': 'error', 'error': str(e)}

        # æ’å…¥æ–°çš„è¯­ä¹‰æ•°æ®
        insert_data = {
            "baseline_type": baseline_type,
            "name": name,
            "version": 1,
            "is_active": True,
            "baseline_data": semantic_data,  # åªåŒ…å«äººç±»å¯è¯»çš„æ•°æ®ï¼Œä¸åŒ…å«å‘é‡
            "source_hash": source_hash
        }

        try:
            result = self.supabase.table("semantic_baselines") \
                .insert(insert_data) \
                .execute()

            logger.info(f"âœ… æˆåŠŸä¸Šä¼ è¯­ä¹‰åŸºçº¿: {name}")
            return {'status': 'uploaded', 'id': result.data[0]['id']}
        except Exception as e:
            logger.error(f"âŒ ä¸Šä¼ è¯­ä¹‰åŸºçº¿ {name} å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}

    def _upload_vector_data(self, baseline_id: int, vector_data: Dict) -> Dict:
        """ä¸Šä¼ å‘é‡æ•°æ®åˆ° baseline_vectors è¡¨"""
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥baseline_idçš„å‘é‡æ•°æ®
        try:
            result = self.supabase.table("baseline_vectors") \
                .select("*") \
                .eq("baseline_id", baseline_id) \
                .eq("embedding_model", "all-MiniLM-L6-v2") \
                .execute()

            if result.data:
                logger.info(f"å‘é‡æ•°æ® baseline_id={baseline_id} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸Šä¼ ")
                return {'status': 'exists', 'id': result.data[0]['id']}
        except Exception as e:
            logger.error(f"æ£€æŸ¥å‘é‡æ•°æ® baseline_id={baseline_id} æ—¶å‡ºé”™: {e}")
            return {'status': 'error', 'error': str(e)}

        # æ’å…¥æ–°çš„å‘é‡æ•°æ®
        insert_data = {
            "baseline_id": baseline_id,
            "embedding_model": "all-MiniLM-L6-v2",
            "vectors_data": vector_data  # åŒ…å«æ‰€æœ‰å‘é‡ç›¸å…³æ•°æ®
        }

        try:
            result = self.supabase.table("baseline_vectors") \
                .insert(insert_data) \
                .execute()

            logger.info(f"âœ… æˆåŠŸä¸Šä¼ å‘é‡æ•°æ®: baseline_id={baseline_id}")
            return {'status': 'uploaded', 'id': result.data[0]['id']}
        except Exception as e:
            logger.error(f"âŒ ä¸Šä¼ å‘é‡æ•°æ® baseline_id={baseline_id} å¤±è´¥: {e}")
            return {'status': 'error', 'error': str(e)}

    def _calculate_hash(self, data: dict) -> str:
        """è®¡ç®—æ•°æ®å“ˆå¸Œå€¼"""
        return hashlib.sha256(json.dumps(data, sort_keys=True).encode()).hexdigest() 