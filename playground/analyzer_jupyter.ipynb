{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ å¼€å§‹åŒè¯­æ–™åº“å¯¹æ¯”æ³•å¼‚å¸¸æ£€æµ‹...\n",
      "âœ… æˆåŠŸåŠ è½½ 217 æ¡èŒä½æ•°æ®\n",
      "âœ… ç­›é€‰å‡º 156 ä¸ªæŠ€æœ¯ç›¸å…³èŒä½\n",
      "âš ï¸ é™åˆ¶å¤„ç†å‰ 10 ä¸ªèŒä½ä»¥ä¾¿å¿«é€ŸéªŒè¯\n",
      "âœ… å·²åŠ è½½å¾·è¯­æ¨¡åž‹\n",
      "ðŸ” è®¡ç®—å…¨å±€IDFå€¼...\n",
      "âœ… è®¡ç®—å®Œæˆï¼ŒèŽ·å¾— 344 ä¸ªè¯çš„IDFå€¼\n",
      "ðŸ” æœ€é€šç”¨çš„è¯æ±‡ (ä½ŽIDF): ['uns', 'deine', 'einem', 'oder', 'als', 'bereich', 'dein', 'dich', 'dir', 'teams']\n",
      "ðŸ·ï¸ è¿›è¡Œè¡Œä¸šåˆ†ç±»...\n",
      "ðŸ“Š è¡Œä¸šåˆ†å¸ƒ: {'tech': np.int64(6), 'media': np.int64(3), 'finance': np.int64(1)}\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: teil (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: teamarbeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: gelegenheit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: group (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bieten (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bereich (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: entwicklung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: fokus (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kund (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: unterstÃ¼tzen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bearbeitung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: unterstÃ¼tzung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: human (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: aufbereitung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: auswertung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: tools (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: runden (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: studiengang (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: verfÃ¼gst (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeitsweise (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: teamfÃ¤higkeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mÃ¼nchen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: spaÃŸ (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: lernen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bewirb (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mentoring (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeitszeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: vergÃ¼tung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: studierende (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: standort (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: dauer (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: monate (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: fragen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: chancengleichheit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: innen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: persÃ¶nlichkeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: deutschland (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: abschlussarbeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: teamarbeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: gelegenheit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: group (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bereich (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kund (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bearbeitung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: human (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: tools (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: runden (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: verfÃ¼gst (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeitsweise (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: teamfÃ¤higkeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: lernen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mentoring (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: weiterentwicklung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: flexibel (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeitszeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: vergÃ¼tung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: studierende (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: standort (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: dauer (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: monate (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: fragen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: chancengleichheit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: innen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: abschlussarbeit (IDFè¿‡ä½Ž)\n",
      "âœ… BMW (tech) | ç‰¹è‰²è¯:8 | è¡Œä¸šè¯:8 | é«˜è´¨é‡:14\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: unterstÃ¼tzung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: planung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: organisation (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: events (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: social (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: erstellung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: auswertung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: marketing (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: profil (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bereich (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: studiengang (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: auffassungsgabe (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeitsweise (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: verfÃ¼gung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: stehen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: deutschkenntnisse (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: wort (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: schrift (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: runden (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: flexibel (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeitszeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: studium (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: erhalten (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: Ã¼bernehmen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: raum (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: interesse (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bewerbungsprozess (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: tel (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeiten (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: industrie (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: entwicklung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: business (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mobil (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: software (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: macht (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: planung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: organisation (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: events (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: social (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: auswertung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: marketing (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: profil (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: studiengang (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: auffassungsgabe (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeitsweise (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: verfÃ¼gung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: stehen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: deutschkenntnisse (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: wort (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: schrift (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: runden (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: erhalten (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: Ã¼bernehmen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: monat (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: raum (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: interesse (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bewerbungsprozess (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bewerbung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: tel (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: industrie (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: entwicklung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: business (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mobil (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: software (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: macht (IDFè¿‡ä½Ž)\n",
      "âœ… Membrain GmbH (media) | ç‰¹è‰²è¯:8 | è¡Œä¸šè¯:8 | é«˜è´¨é‡:10\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: dein (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kreativ (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: content (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: corporate (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: design (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: unterstÃ¼tzen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: konzeption (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: umsetzung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: tagesgeschÃ¤ft (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: studium (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: studiengang (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: umgang (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: adobe (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: cloud (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: erstellung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: video (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: abschlussarbeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: unterstÃ¼tzung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mentoring (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: chance (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: einzubringen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: teil (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: stehen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: frau (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: verfÃ¼gung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bewerben (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: dein (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kreativ (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: content (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: corporate (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: design (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: konzeption (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: umsetzung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: tagesgeschÃ¤ft (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: studiengang (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: umgang (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: adobe (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: cloud (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: erstellung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: video (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: abschlussarbeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mentoring (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: chance (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: einzubringen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bewerbung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: stehen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: frau (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: verfÃ¼gung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bewerben (IDFè¿‡ä½Ž)\n",
      "âœ… DATA MODUL (media) | ç‰¹è‰²è¯:8 | è¡Œä¸šè¯:8 | é«˜è´¨é‡:16\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: woche (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: industrie (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: betreuung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bearbeitung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: identifikation (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: planung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: vorbereitung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: suchst (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: zusammenarbeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mÃ¶chtest (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: einblick (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: talent (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: recruiting (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: spaÃŸ (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeiten (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: auffassungsgabe (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kreativitÃ¤t (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: wort (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bÃ¼ro (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mÃ¼nchner (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: flexibilitÃ¤t (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeite (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: zukunft (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: urban (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: club (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mitgliedschaft (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mobil (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: massage (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bewerben (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: potenzial (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: umfeld (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: teamarbeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: gemeinsam (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: gestalten (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: innen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeiten (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kreativitÃ¤t (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bÃ¼ro (IDFè¿‡ä½Ž)\n",
      "âœ… Germanedge Solutions GmbH (tech) | ç‰¹è‰²è¯:8 | è¡Œä¸šè¯:8 | é«˜è´¨é‡:12\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: werkstudent (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: organisation (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: unternehmenskultur (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: wert (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kannst (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: geschick (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: vorbereitung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: durchfÃ¼hrung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: prÃ¼fung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: unterstÃ¼tzung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: tagesgeschÃ¤ft (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: eigenstÃ¤ndig (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bearbeitung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: teams (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: profil (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeitest (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: auge (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: spaÃŸ (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeitsweise (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bieten (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: legen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: dein (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: perspektive (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: corporate (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bewerben (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: lernen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: vielfalt (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: gestalten (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: unsere (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kund (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: innen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: online (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: einzubringen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: freuen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: fragen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: willst (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kontakt (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: findest (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: blick (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: wert (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kannst (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: unterstÃ¼tzung (IDFè¿‡ä½Ž)\n",
      "âœ… VIU Deutschland GmbH (tech) | ç‰¹è‰²è¯:8 | è¡Œä¸šè¯:7 | é«˜è´¨é‡:12\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: woche (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: standort (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mÃ¶chtest (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: suchen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: werkstudent (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: erstellung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kreativitÃ¤t (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: durchfÃ¼hrung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: analysen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: verstehen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: entwicklung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kreativ (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: umsetzung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: perspektive (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: portfolio (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: geschick (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: tools (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: adobe (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: englischkenntnisse (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bÃ¼ro (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: events (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: gemeinsam (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: urban (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: club (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: weiterentwicklung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: flexibel (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: standort (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mÃ¶chtest (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: erstellung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kreativitÃ¤t (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: durchfÃ¼hrung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: analysen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: verstehen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kreativ (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: umsetzung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: perspektive (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: portfolio (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: geschick (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: tools (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: adobe (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: englischkenntnisse (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bÃ¼ro (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: events (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: gemeinsam (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: urban (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: club (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: weiterentwicklung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: flexibel (IDFè¿‡ä½Ž)\n",
      "âœ… adabay GmbH (tech) | ç‰¹è‰²è¯:8 | è¡Œä¸šè¯:8 | é«˜è´¨é‡:11\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: raum (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: deutschland (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: werkstudent (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: analyse (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: teil (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: suchen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: identifikation (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: blick (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: suchst (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: werkstudierendentÃ¤tigkeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: auge (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: umgang (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: office (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: tools (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: interesse (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: prozessen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeitest (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: deutschkenntnisse (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: potenzial (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: Ã¼bernehmen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: schaffen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kannst (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: chance (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: corporate (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: lernen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: netzwerk (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: freuen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: raum (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: werkstudent (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: analyse (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: standort (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: identifikation (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: blick (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: suchst (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: werkstudierendentÃ¤tigkeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: auge (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: office (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: tools (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: interesse (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: prozessen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: deutschkenntnisse (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: potenzial (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: Ã¼bernehmen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: schaffen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kannst (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: chance (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: flexibel (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: corporate (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: weiterentwicklung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: lernen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bÃ¼ro (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: netzwerk (IDFè¿‡ä½Ž)\n",
      "âœ… StrÃ¶er SE & Co. KGaA (tech) | ç‰¹è‰²è¯:8 | è¡Œä¸šè¯:8 | é«˜è´¨é‡:13\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: crm (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: teams (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: werkstudent (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: richtig (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: office (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mÃ¼nchen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bewirb (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: durchfÃ¼hrung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: blick (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: tests (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeitest (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: masterstudium (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: fokus (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kommunikation (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bringst (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: spaÃŸ (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: deutsch (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: ganz (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: verstehen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: frage (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: stellen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bieten (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: unternehmenskultur (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: umfeld (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeite (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: deutschlandweit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mitgliedschaft (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: urban (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: club (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kostenlosen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: einblick (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bekommst (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: woche (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: dauer (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: monat (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: weiterentwicklung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: findest (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mail (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: group (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: portfolio (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: richtig (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bewirb (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: deutsch (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: monat (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bewerbung (IDFè¿‡ä½Ž)\n",
      "âœ… Joyn GmbH (media) | ç‰¹è‰²è¯:8 | è¡Œä¸šè¯:8 | é«˜è´¨é‡:16\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: mÃ¼nchen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: dein (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: studium (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: teil (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: suchen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: tagesgeschÃ¤ft (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: controlling (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: erstellung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: betriebswirtschaftslehre (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: studiengang (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: excel (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeitsweise (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: flexibilitÃ¤t (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: sicheres (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: auftreten (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kreativitÃ¤t (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: runden (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: flexibel (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeitszeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: werkstudierendentÃ¤tigkeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeitest (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: stehen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: frage (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: verfÃ¼gung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: betreuung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: corporate (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: unternehmenskultur (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: gemeinsam (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: freuen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: bewerben (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: lernen (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: video (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: angebot (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: studierende (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kannst (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: kontakt (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: frau (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: group (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: studium (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: erstellung (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: flexibel (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: arbeitszeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: werkstudierendentÃ¤tigkeit (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: frage (IDFè¿‡ä½Ž)\n",
      "ðŸš« é€šç”¨è¯æƒ©ç½š: video (IDFè¿‡ä½Ž)\n",
      "âœ… msg nexinsure ag (tech) | ç‰¹è‰²è¯:8 | è¡Œä¸šè¯:8 | é«˜è´¨é‡:16\n",
      "âš ï¸ è·³è¿‡ Siemens: è¯­æ–™åº“ä¸è¶³ (åŒè¡Œ:0, å¤–è¡Œ:9)\n",
      "\n",
      "ðŸŽ‰ åŒè¯­æ–™åº“å¯¹æ¯”æ³•æ£€æµ‹å®Œæˆ!\n",
      "ðŸ“Š ç»“æžœç»Ÿè®¡:\n",
      "   - å¤„ç†èŒä½æ•°: 9\n",
      "   - å¹³å‡è´¨é‡æ¯”ä¾‹: 83.9%\n",
      "   - é«˜è´¨é‡å¼‚å¸¸è¯æ€»æ•°: 120\n",
      "   - è¡Œä¸šåˆ†å¸ƒ: {'tech': np.int64(6), 'media': np.int64(3)}\n",
      "ðŸ“ ç»“æžœå·²ä¿å­˜è‡³: dual_corpus_enhanced_results.json\n",
      "\n",
      "ðŸ” è´¨é‡åˆ†æžæŠ¥å‘Š:\n",
      "\n",
      "ðŸ“‹ BMW (tech):\n",
      "  ðŸŽ¯ ç‰¹è‰²è¯æ±‡: ['factor', 'realfahrzeugstudien', 'automotive']\n",
      "  ðŸ·ï¸ è¡Œä¸šæ ‡å¿—: ['factor', 'realfahrzeugstudien', 'automotive']\n",
      "\n",
      "ðŸ“‹ Membrain GmbH (media):\n",
      "  ðŸŽ¯ ç‰¹è‰²è¯æ±‡: ['kommunikationswissenschaft', 'international']\n",
      "  ðŸ·ï¸ è¡Œä¸šæ ‡å¿—: ['kommunikationswissenschaft', 'international', 'webinaren']\n",
      "\n",
      "ðŸ“‹ DATA MODUL (media):\n",
      "  ðŸŽ¯ ç‰¹è‰²è¯æ±‡: ['neu kommunikationsmaÃŸnahme', 'kommunikationsmaÃŸnahme unterstÃ¼tzen', 'vielfÃ¤ltig tagesgeschÃ¤ft']\n",
      "  ðŸ·ï¸ è¡Œä¸šæ ‡å¿—: ['neu kommunikationsmaÃŸnahme', 'kommunikationsmaÃŸnahme unterstÃ¼tzen', 'vielfÃ¤ltig tagesgeschÃ¤ft']\n",
      "\n",
      "ðŸ“‹ Germanedge Solutions GmbH (tech):\n",
      "  ðŸŽ¯ ç‰¹è‰²è¯æ±‡: ['mensch', 'digital produktion', 'euro prÃ¤mie']\n",
      "  ðŸ·ï¸ è¡Œä¸šæ ‡å¿—: ['digital produktion', 'digital', 'produktion']\n",
      "\n",
      "ðŸ“‹ VIU Deutschland GmbH (tech):\n",
      "  ðŸŽ¯ ç‰¹è‰²è¯æ±‡: ['werkstatt', 'operation', 'werkstattlogistik']\n",
      "  ðŸ·ï¸ è¡Œä¸šæ ‡å¿—: ['werkstatt', 'brill', 'arbeitsumfeld']\n",
      "\n",
      "ðŸ“‹ adabay GmbH (tech):\n",
      "  ðŸŽ¯ ç‰¹è‰²è¯æ±‡: ['fair', 'stunde', 'digital produkt']\n",
      "  ðŸ·ï¸ è¡Œä¸šæ ‡å¿—: ['fair', 'digital produkt', 'digital']\n",
      "\n",
      "ðŸ“‹ StrÃ¶er SE & Co. KGaA (tech):\n",
      "  ðŸŽ¯ ç‰¹è‰²è¯æ±‡: ['daten', 'analys', 'trainingsangebot']\n",
      "  ðŸ·ï¸ è¡Œä¸šæ ‡å¿—: ['detail', 'daten', 'analys']\n",
      "\n",
      "ðŸ“‹ Joyn GmbH (media):\n",
      "  ðŸŽ¯ ç‰¹è‰²è¯æ±‡: ['entertainment', 'e-mail', 'customer']\n",
      "  ðŸ·ï¸ è¡Œä¸šæ ‡å¿—: ['kampagne', 'kunde', 'mÃ¶glichkeit']\n",
      "\n",
      "ðŸ“‹ msg nexinsure ag (tech):\n",
      "  ðŸŽ¯ ç‰¹è‰²è¯æ±‡: ['all', 'genders', 'e-mail']\n",
      "  ðŸ·ï¸ è¡Œä¸šæ ‡å¿—: ['fÃ¼hrend anbieter', 'anbieter softwar', 'softwar beratung']\n",
      "\n",
      "ðŸ“Š æœ€å¸¸æ£€æµ‹åˆ°çš„ç‰¹è‰²æœ¯è¯­: [('fair', 3), ('e-mail', 3), ('international', 2), ('detail', 2), ('factor', 1)]\n",
      "ðŸ“Š æœ€å¸¸æ£€æµ‹åˆ°çš„è¡Œä¸šæœ¯è¯­: [('fair', 2), ('international', 2), ('digital', 2), ('factor', 1), ('realfahrzeugstudien', 1)]\n",
      "\n",
      "=== åŒè¯­æ–™åº“å¯¹æ¯”æ³•æ•ˆæžœé¢„è§ˆ ===\n",
      "ðŸ¢ å…¬å¸: BMW\n",
      "ðŸ“‹ èŒä½: Werkstudent Realfahrzeugstudien und Human Factors (w/m/x)\n",
      "ðŸ·ï¸ è¡Œä¸š: tech\n",
      "ðŸ“Š è´¨é‡æŒ‡æ ‡: {'specialist_anomalies_count': 8, 'industry_markers_count': 8, 'total_anomalies': 16, 'high_quality_anomalies': 14, 'quality_ratio': 0.88}\n",
      "\n",
      "ðŸŽ¯ ä¸ŽåŒè¡Œå¯¹æ¯”å‘çŽ°çš„ç‰¹è‰²è¯æ±‡:\n",
      "  â€¢ factor (å¼‚å¸¸æ¯”ä¾‹: 60.24x, è´¨é‡åˆ†: 3.0)\n",
      "  â€¢ realfahrzeugstudien (å¼‚å¸¸æ¯”ä¾‹: 60.24x, è´¨é‡åˆ†: 3.0)\n",
      "  â€¢ automotive (å¼‚å¸¸æ¯”ä¾‹: 60.24x, è´¨é‡åˆ†: 3.0)\n",
      "\n",
      "ðŸ·ï¸ ä¸Žå¤–è¡Œå¯¹æ¯”å‘çŽ°çš„è¡Œä¸šæ ‡å¿—:\n",
      "  â€¢ factor (å¼‚å¸¸æ¯”ä¾‹: 60.24x, è´¨é‡åˆ†: 4.0)\n",
      "  â€¢ realfahrzeugstudien (å¼‚å¸¸æ¯”ä¾‹: 60.24x, è´¨é‡åˆ†: 4.0)\n",
      "  â€¢ automotive (å¼‚å¸¸æ¯”ä¾‹: 60.24x, è´¨é‡åˆ†: 4.0)\n",
      "\n",
      "âœ… åŒè¯­æ–™åº“å¯¹æ¯”æ³•å®žçŽ°å®Œæˆ!\n",
      "ðŸš€ æ ¸å¿ƒæ”¹è¿›:\n",
      "   âœ“ åŒè¡Œå¯¹æ¯”æ‰¾ç‰¹è‰² (specialist_anomalies)\n",
      "   âœ“ å¤–è¡Œå¯¹æ¯”æ‰¾è¡Œä¸šåŸºå›  (industry_markers)\n",
      "   âœ“ åŸºäºŽIDFçš„æ™ºèƒ½é€šç”¨è¯è¿‡æ»¤\n",
      "   âœ“ è¡Œä¸šè‡ªåŠ¨åˆ†ç±»ç³»ç»Ÿ\n",
      "   âœ“ ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è´¨é‡è¯„åˆ†\n",
      "\n",
      "ðŸŽ¯ ä¸‹ä¸€æ­¥å»ºè®®:\n",
      "1. åœ¨10ä¸ªHRè¯„ä¼°çš„èŒä½ä¸Šæµ‹è¯•æ–°ç®—æ³•\n",
      "2. å¯¹æ¯”æ–°æ—§ç»“æžœï¼ŒéªŒè¯'ESG'ã€'international'ç­‰å…³é”®è¯çš„æ£€æµ‹æ•ˆæžœ\n",
      "3. è°ƒæ•´IDFé˜ˆå€¼å’Œè´¨é‡è¯„åˆ†æƒé‡\n",
      "4. å‡†å¤‡é«˜è´¨é‡ç»“æžœè¾“å…¥åˆ°LLMè¿›è¡Œè¯­ä¹‰åˆ†æž\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EnhancedJobAnomalyDetector:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Phase 1.0: åŒè¯­æ–™åº“å¯¹æ¯”æ³• + æ™ºèƒ½é€šç”¨è¯è¿‡æ»¤\n",
    "        \"\"\"\n",
    "        # åŠ è½½å¾·è¯­NLPæ¨¡åž‹\n",
    "        try:\n",
    "            self.nlp = spacy.load(\"de_core_news_sm\")\n",
    "            print(\"âœ… å·²åŠ è½½å¾·è¯­æ¨¡åž‹\")\n",
    "        except OSError:\n",
    "            try:\n",
    "                self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "                print(\"âš ï¸ å¾·è¯­æ¨¡åž‹æœªæ‰¾åˆ°ï¼Œä½¿ç”¨è‹±è¯­æ¨¡åž‹\")\n",
    "            except OSError:\n",
    "                print(\"âŒ è¯·å®‰è£…spacyæ¨¡åž‹: python -m spacy download de_core_news_sm\")\n",
    "                raise\n",
    "        \n",
    "        # æ‰©å±•çš„å¾·è‹±åœç”¨è¯è¡¨\n",
    "        self.stop_words = {\n",
    "            # å¾·è¯­åœç”¨è¯\n",
    "            'und', 'der', 'die', 'das', 'fÃ¼r', 'von', 'mit', 'bei', 'den', 'dem', 'des', \n",
    "            'ein', 'eine', 'einen', 'einer', 'sich', 'wir', 'sie', 'ihr', 'ich', 'du',\n",
    "            'ist', 'sind', 'war', 'waren', 'haben', 'hat', 'wird', 'werden', 'kann',\n",
    "            'soll', 'sollte', 'muss', 'auf', 'zu', 'nach', 'Ã¼ber', 'unter', 'durch',\n",
    "            \n",
    "            # è‹±è¯­åœç”¨è¯\n",
    "            'the', 'and', 'for', 'with', 'are', 'you', 'will', 'can', 'have', 'your', \n",
    "            'our', 'this', 'that', 'work', 'working', 'job', 'position', 'role',\n",
    "            'also', 'access', 'employees', 'company', 'team', 'opportunity',\n",
    "            'during', 'right', 'therefore', 'should', 'needed', 'responsible',\n",
    "            'something', 'experience', 'skills', 'requirements', 'candidates',\n",
    "            \n",
    "            # æ‹›è˜é¢†åŸŸé€šç”¨è¯\n",
    "            'experience', 'skills', 'requirements', 'candidate', 'candidates',\n",
    "            'position', 'role', 'job', 'work', 'working', 'opportunity',\n",
    "            'team', 'company', 'employees', 'department', 'organization',\n",
    "            'responsibilities', 'tasks', 'duties', 'qualifications',\n",
    "            'background', 'knowledge', 'ability', 'abilities', 'capable',\n",
    "            \n",
    "            # å¾·è¯­æ‹›è˜é€šç”¨è¯\n",
    "            'stelle', 'position', 'arbeitsplatz', 'mitarbeiter', 'team',\n",
    "            'unternehmen', 'firma', 'aufgaben', 'anforderungen', 'qualifikationen',\n",
    "            'erfahrung', 'kenntnisse', 'fÃ¤higkeiten', 'verantwortung',\n",
    "        }\n",
    "        \n",
    "        # å…¬å¸åå¸¸è§åŽç¼€/æ ‡è¯†ç¬¦\n",
    "        self.company_suffixes = {\n",
    "            'gmbh', 'ag', 'kg', 'ohg', 'gbr', 'ug', 'eg', 'ev', \n",
    "            'inc', 'corp', 'ltd', 'llc', 'co', 'company', 'group',\n",
    "            'holding', 'ventures', 'capital', 'partners', 'solutions',\n",
    "            'technologies', 'systems', 'services', 'consulting',\n",
    "            'verlag', 'verlagsgruppe', 'media', 'publishing'\n",
    "        }\n",
    "        \n",
    "        # å™ªéŸ³æ¨¡å¼\n",
    "        self.noise_patterns = [\n",
    "            r'\\w*_date_?\\d*',     # publication_date_10\n",
    "            r'job_id_?\\d*',       # job_id_123  \n",
    "            r'location_\\w+',      # location_munich\n",
    "            r'\\d{4,}',            # é•¿æ•°å­—ID\n",
    "            r'publication_date',   # æ˜Žç¡®è¿‡æ»¤\n",
    "            r'legal_entity',      # æ³•å¾‹å®žä½“\n",
    "            r'^.{1,2}$',         # 1-2å­—ç¬¦çš„è¯\n",
    "            r'^\\d+$',            # çº¯æ•°å­—\n",
    "            r'^[a-z]$',          # å•å­—æ¯\n",
    "            r'http[s]?://.*',    # URL\n",
    "            r'.*@.*\\..*',        # é‚®ç®±\n",
    "        ]\n",
    "        \n",
    "        # æœ‰æ„ä¹‰çš„è¯æ€§æ ‡ç­¾\n",
    "        self.meaningful_pos = {\n",
    "            'NOUN', 'PROPN',     # åè¯ã€ä¸“æœ‰åè¯\n",
    "            'ADJ',               # å½¢å®¹è¯  \n",
    "            'VERB',              # åŠ¨è¯\n",
    "            'NUM'                # æ•°å­—\n",
    "        }\n",
    "        \n",
    "        # å…¨å±€IDFç¼“å­˜\n",
    "        self.global_idf_cache = None\n",
    "        \n",
    "        # è¡Œä¸šåˆ†ç±»ç¼“å­˜\n",
    "        self.industry_cache = {}\n",
    "        \n",
    "    def classify_job_industry(self, company_name, job_title, description):\n",
    "        \"\"\"\n",
    "        èŒä½è¡Œä¸šåˆ†ç±» - ç”¨äºŽåŒè¯­æ–™åº“å¯¹æ¯”\n",
    "        \"\"\"\n",
    "        cache_key = f\"{company_name}_{job_title}\"\n",
    "        if cache_key in self.industry_cache:\n",
    "            return self.industry_cache[cache_key]\n",
    "        \n",
    "        # ç»„åˆæ‰€æœ‰æ–‡æœ¬è¿›è¡Œåˆ†æž\n",
    "        combined_text = f\"{company_name} {job_title} {description}\".lower()\n",
    "        \n",
    "        # è¡Œä¸šå…³é”®è¯æ˜ å°„\n",
    "        industry_keywords = {\n",
    "            'consulting': [\n",
    "                'consulting', 'mckinsey', 'bcg', 'bain', 'strategy', 'consultant',\n",
    "                'beratung', 'strategieberatung', 'unternehmensberatung'\n",
    "            ],\n",
    "            'finance': [\n",
    "                'bank', 'financial', 'investment', 'finance', 'asset', 'trading',\n",
    "                'fund', 'capital', 'fintech', 'esg', 'sustainable', 'risk',\n",
    "                'banking', 'wealth', 'portfolio', 'credit'\n",
    "            ],\n",
    "            'tech': [\n",
    "                'software', 'technology', 'tech', 'ai', 'machine learning',\n",
    "                'data science', 'developer', 'engineering', 'cloud', 'devops',\n",
    "                'digital', 'innovation', 'platform', 'algorithm'\n",
    "            ],\n",
    "            'law': [\n",
    "                'law', 'legal', 'attorney', 'lawyer', 'litigation', 'compliance',\n",
    "                'regulatory', 'recht', 'rechtsanwalt', 'kanzlei', 'jurist'\n",
    "            ],\n",
    "            'automotive': [\n",
    "                'automotive', 'car', 'vehicle', 'bmw', 'mercedes', 'porsche',\n",
    "                'audi', 'volkswagen', 'mobility', 'transport'\n",
    "            ],\n",
    "            'healthcare': [\n",
    "                'health', 'medical', 'pharmaceutical', 'biotech', 'clinical',\n",
    "                'patient', 'hospital', 'healthcare', 'medicine'\n",
    "            ],\n",
    "            'media': [\n",
    "                'media', 'publishing', 'journalism', 'content', 'editorial',\n",
    "                'marketing', 'communication', 'pr', 'Ã¶ffentlichkeitsarbeit'\n",
    "            ],\n",
    "            'real_estate': [\n",
    "                'real estate', 'property', 'immobilien', 'proptech', 'construction',\n",
    "                'building', 'development', 'housing'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # è®¡ç®—æ¯ä¸ªè¡Œä¸šçš„åŒ¹é…åˆ†æ•°\n",
    "        industry_scores = {}\n",
    "        for industry, keywords in industry_keywords.items():\n",
    "            score = sum(1 for keyword in keywords if keyword in combined_text)\n",
    "            if score > 0:\n",
    "                industry_scores[industry] = score\n",
    "        \n",
    "        # è¿”å›žå¾—åˆ†æœ€é«˜çš„è¡Œä¸šï¼Œå¦‚æžœæ²¡æœ‰æ˜Žç¡®åŒ¹é…åˆ™è¿”å›ž'general'\n",
    "        if industry_scores:\n",
    "            classified_industry = max(industry_scores, key=industry_scores.get)\n",
    "        else:\n",
    "            classified_industry = 'general'\n",
    "        \n",
    "        self.industry_cache[cache_key] = classified_industry\n",
    "        return classified_industry\n",
    "    \n",
    "    def calculate_global_idf(self, jobs_df):\n",
    "        \"\"\"\n",
    "        è®¡ç®—å…¨å±€IDFå€¼ï¼Œç”¨äºŽæ™ºèƒ½é€šç”¨è¯è¿‡æ»¤\n",
    "        \"\"\"\n",
    "        if self.global_idf_cache is not None:\n",
    "            return self.global_idf_cache\n",
    "        \n",
    "        print(\"ðŸ” è®¡ç®—å…¨å±€IDFå€¼...\")\n",
    "        \n",
    "        # æ”¶é›†æ‰€æœ‰æ–‡æœ¬\n",
    "        all_texts = []\n",
    "        for _, row in jobs_df.iterrows():\n",
    "            description = str(row.get('description', ''))\n",
    "            if description and len(description.strip()) > 50:\n",
    "                all_texts.append(description)\n",
    "        \n",
    "        if len(all_texts) < 5:\n",
    "            print(\"âš ï¸ æ–‡æœ¬æ•°é‡ä¸è¶³ï¼Œè·³è¿‡IDFè®¡ç®—\")\n",
    "            return {}\n",
    "        \n",
    "        # ä½¿ç”¨TF-IDFè®¡ç®—IDFå€¼\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            max_features=10000,\n",
    "            stop_words=list(self.stop_words),\n",
    "            ngram_range=(1, 1),\n",
    "            min_df=2,  # è‡³å°‘åœ¨2ä¸ªæ–‡æ¡£ä¸­å‡ºçŽ°\n",
    "            token_pattern=r'\\b[a-zA-ZÃ¤Ã¶Ã¼Ã„Ã–ÃœÃŸ]{3,}\\b'\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            vectorizer.fit(all_texts)\n",
    "            \n",
    "            # æå–IDFå€¼\n",
    "            feature_names = vectorizer.get_feature_names_out()\n",
    "            idf_values = vectorizer.idf_\n",
    "            \n",
    "            idf_dict = dict(zip(feature_names, idf_values))\n",
    "            self.global_idf_cache = idf_dict\n",
    "            \n",
    "            print(f\"âœ… è®¡ç®—å®Œæˆï¼ŒèŽ·å¾— {len(idf_dict)} ä¸ªè¯çš„IDFå€¼\")\n",
    "            \n",
    "            # æ˜¾ç¤ºä¸€äº›ä½ŽIDFï¼ˆé«˜é¢‘é€šç”¨è¯ï¼‰çš„ä¾‹å­\n",
    "            sorted_idf = sorted(idf_dict.items(), key=lambda x: x[1])\n",
    "            print(f\"ðŸ” æœ€é€šç”¨çš„è¯æ±‡ (ä½ŽIDF): {[word for word, idf in sorted_idf[:10]]}\")\n",
    "            \n",
    "            return idf_dict\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ IDFè®¡ç®—å¤±è´¥: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def is_generic_word(self, word, idf_threshold=2.5):\n",
    "        \"\"\"\n",
    "        åŸºäºŽIDFå€¼åˆ¤æ–­æ˜¯å¦ä¸ºé€šç”¨è¯\n",
    "        IDFå€¼è¶Šä½Ž = åœ¨è¶Šå¤šæ–‡æ¡£ä¸­å‡ºçŽ° = è¶Šé€šç”¨\n",
    "        \"\"\"\n",
    "        if not self.global_idf_cache:\n",
    "            return False\n",
    "        \n",
    "        idf_value = self.global_idf_cache.get(word.lower(), float('inf'))\n",
    "        return idf_value < idf_threshold\n",
    "    \n",
    "    def extract_company_terms(self, company_name):\n",
    "        \"\"\"\n",
    "        å¼ºåŒ–ç‰ˆå…¬å¸åè¯æ±‡æå–\n",
    "        \"\"\"\n",
    "        if not company_name or pd.isna(company_name):\n",
    "            return set()\n",
    "        \n",
    "        company_terms = set()\n",
    "        company_name = str(company_name).lower()\n",
    "        \n",
    "        # 1. ä½¿ç”¨spaCyè¿›è¡Œå‘½åå®žä½“è¯†åˆ«\n",
    "        try:\n",
    "            doc = self.nlp(company_name)\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ in ['ORG', 'PERSON']:\n",
    "                    words = re.findall(r'\\b[a-zA-ZÃ¤Ã¶Ã¼Ã„Ã–ÃœÃŸ]{2,}\\b', ent.text.lower())\n",
    "                    company_terms.update(words)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 2. ç›´æŽ¥åˆ†è§£å…¬å¸å\n",
    "        cleaned_name = re.sub(r'\\([^)]*\\)', '', company_name)\n",
    "        cleaned_name = re.sub(r'[^\\w\\s\\-]', ' ', cleaned_name)\n",
    "        \n",
    "        words = re.findall(r'\\b[a-zA-ZÃ¤Ã¶Ã¼Ã„Ã–ÃœÃŸ]{2,}\\b', cleaned_name)\n",
    "        company_terms.update(words)\n",
    "        \n",
    "        # 3. ç§»é™¤å¸¸è§åŽç¼€ï¼Œä½†è®°å½•ä¸»è¦éƒ¨åˆ†\n",
    "        filtered_terms = set()\n",
    "        for word in company_terms:\n",
    "            if word not in self.company_suffixes:\n",
    "                filtered_terms.add(word)\n",
    "            else:\n",
    "                filtered_terms.add(word)\n",
    "        \n",
    "        return filtered_terms\n",
    "    \n",
    "    def advanced_text_preprocessing(self, text, company_terms_to_filter=None):\n",
    "        \"\"\"\n",
    "        é«˜çº§æ–‡æœ¬é¢„å¤„ç†\n",
    "        \"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return [], []\n",
    "        \n",
    "        if company_terms_to_filter is None:\n",
    "            company_terms_to_filter = set()\n",
    "        \n",
    "        # 1. åŸºç¡€æ¸…æ´—\n",
    "        text = str(text)\n",
    "        \n",
    "        # ä¿®å¤å¸¸è§çš„æ‹¼æŽ¥é—®é¢˜\n",
    "        text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)\n",
    "        text = re.sub(r'([a-zA-Z])(\\d)', r'\\1 \\2', text)\n",
    "        text = re.sub(r'(\\d)([a-zA-Z])', r'\\1 \\2', text)\n",
    "        \n",
    "        # å¤„ç†æ ‡ç‚¹å’Œç‰¹æ®Šå­—ç¬¦\n",
    "        text = re.sub(r'[^\\w\\s\\-/]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = text.strip().lower()\n",
    "        \n",
    "        # 2. ä½¿ç”¨spaCyè¿›è¡Œé«˜çº§å¤„ç†\n",
    "        doc = self.nlp(text)\n",
    "        \n",
    "        unigrams = []\n",
    "        bigrams = []\n",
    "        \n",
    "        # è¿‡æ»¤tokens\n",
    "        valid_tokens = []\n",
    "        for token in doc:\n",
    "            # è·³è¿‡æ ‡ç‚¹ã€ç©ºæ ¼ã€åœç”¨è¯\n",
    "            if (token.is_punct or token.is_space or \n",
    "                token.text.lower() in self.stop_words or\n",
    "                self.is_noise_pattern(token.text) or\n",
    "                token.pos_ not in self.meaningful_pos):\n",
    "                continue\n",
    "            \n",
    "            # ä½¿ç”¨è¯å½¢è¿˜åŽŸ\n",
    "            lemma = token.lemma_.lower().strip()\n",
    "            \n",
    "            # è¿‡æ»¤å…¬å¸åç›¸å…³è¯æ±‡å’ŒçŸ­è¯\n",
    "            if lemma in company_terms_to_filter or len(lemma) < 3:\n",
    "                continue\n",
    "            \n",
    "            valid_tokens.append(lemma)\n",
    "            unigrams.append(lemma)\n",
    "        \n",
    "        # ç”Ÿæˆbigrams\n",
    "        for i in range(len(valid_tokens) - 1):\n",
    "            bigram = f\"{valid_tokens[i]} {valid_tokens[i+1]}\"\n",
    "            \n",
    "            # æ£€æŸ¥bigramæ˜¯å¦åŒ…å«å…¬å¸åè¯æ±‡\n",
    "            bigram_contains_company = any(\n",
    "                company_term in bigram for company_term in company_terms_to_filter\n",
    "            )\n",
    "            \n",
    "            if not bigram_contains_company:\n",
    "                bigrams.append(bigram)\n",
    "        \n",
    "        return unigrams, bigrams\n",
    "    \n",
    "    def is_noise_pattern(self, word):\n",
    "        \"\"\"æ£€æŸ¥æ˜¯å¦ä¸ºå™ªéŸ³æ¨¡å¼\"\"\"\n",
    "        for pattern in self.noise_patterns:\n",
    "            if re.match(pattern, word, re.IGNORECASE):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def detect_anomalies_dual_corpus(self, target_job, specialist_corpus, general_corpus, \n",
    "                                   job_title=\"\", company_name=\"\", industry=\"\"):\n",
    "        \"\"\"\n",
    "        *** æ ¸å¿ƒæ”¹è¿›ï¼šåŒè¯­æ–™åº“å¯¹æ¯”æ³• ***\n",
    "        \n",
    "        Args:\n",
    "            target_job: ç›®æ ‡èŒä½æè¿°\n",
    "            specialist_corpus: åŒè¡Œä¸šèŒä½æè¿°åˆ—è¡¨ (æ‰¾\"ç‰¹è‰²\")\n",
    "            general_corpus: å…¶ä»–è¡Œä¸šèŒä½æè¿°åˆ—è¡¨ (æ‰¾\"è¡Œä¸šåŸºå› \")\n",
    "            job_title: èŒä½æ ‡é¢˜\n",
    "            company_name: å…¬å¸å\n",
    "            industry: è¡Œä¸šåˆ†ç±»\n",
    "        \"\"\"\n",
    "        if not target_job:\n",
    "            return {\"specialist_anomalies\": [], \"industry_markers\": [], \"metadata\": {}}\n",
    "        \n",
    "        # æå–å…¬å¸åç›¸å…³è¯æ±‡ç”¨äºŽè¿‡æ»¤\n",
    "        company_terms = self.extract_company_terms(company_name)\n",
    "        \n",
    "        # é¢„å¤„ç†ç›®æ ‡èŒä½\n",
    "        target_unigrams, target_bigrams = self.advanced_text_preprocessing(\n",
    "            target_job, company_terms\n",
    "        )\n",
    "        \n",
    "        # === å¯¹æ¯”Aï¼šä¸Ž\"åŒè¡Œ\"æ¯”ï¼Œæ‰¾\"ç‰¹è‰²\" ===\n",
    "        specialist_unigrams = []\n",
    "        specialist_bigrams = []\n",
    "        \n",
    "        for job in specialist_corpus:\n",
    "            if job and not pd.isna(job):\n",
    "                uni, bi = self.advanced_text_preprocessing(job)\n",
    "                specialist_unigrams.extend(uni)\n",
    "                specialist_bigrams.extend(bi)\n",
    "        \n",
    "        # === å¯¹æ¯”Bï¼šä¸Ž\"å¤–è¡Œ\"æ¯”ï¼Œæ‰¾\"è¡Œä¸šåŸºå› \" ===\n",
    "        general_unigrams = []\n",
    "        general_bigrams = []\n",
    "        \n",
    "        for job in general_corpus:\n",
    "            if job and not pd.isna(job):\n",
    "                uni, bi = self.advanced_text_preprocessing(job)\n",
    "                general_unigrams.extend(uni)\n",
    "                general_bigrams.extend(bi)\n",
    "        \n",
    "        # è®¡ç®—ç‰¹è‰²å¼‚å¸¸è¯ï¼ˆä¸ŽåŒè¡Œå¯¹æ¯”ï¼‰\n",
    "        specialist_anomalies = self.calculate_anomalies_enhanced(\n",
    "            target_unigrams, target_bigrams,\n",
    "            specialist_unigrams, specialist_bigrams,\n",
    "            job_title, company_name, comparison_type=\"specialist\"\n",
    "        )\n",
    "        \n",
    "        # è®¡ç®—è¡Œä¸šæ ‡å¿—è¯ï¼ˆä¸Žå¤–è¡Œå¯¹æ¯”ï¼‰\n",
    "        industry_markers = self.calculate_anomalies_enhanced(\n",
    "            target_unigrams, target_bigrams,\n",
    "            general_unigrams, general_bigrams,\n",
    "            job_title, company_name, comparison_type=\"industry\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"specialist_anomalies\": specialist_anomalies,\n",
    "            \"industry_markers\": industry_markers,\n",
    "            \"metadata\": {\n",
    "                \"industry\": industry,\n",
    "                \"specialist_corpus_size\": len(specialist_corpus),\n",
    "                \"general_corpus_size\": len(general_corpus),\n",
    "                \"target_unigrams_count\": len(target_unigrams),\n",
    "                \"target_bigrams_count\": len(target_bigrams),\n",
    "                \"company_terms_filtered\": len(company_terms)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def calculate_anomalies_enhanced(self, target_unigrams, target_bigrams, \n",
    "                                   corpus_unigrams, corpus_bigrams,\n",
    "                                   job_title, company_name, comparison_type):\n",
    "        \"\"\"\n",
    "        å¢žå¼ºç‰ˆå¼‚å¸¸è®¡ç®—ï¼Œæ”¯æŒåŒè¯­æ–™åº“å¯¹æ¯”\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # å¤„ç†unigrams\n",
    "        for word_type, target_words, corpus_words in [\n",
    "            (\"unigrams\", target_unigrams, corpus_unigrams),\n",
    "            (\"bigrams\", target_bigrams, corpus_bigrams)\n",
    "        ]:\n",
    "            \n",
    "            target_freq = Counter(target_words)\n",
    "            corpus_freq = Counter(corpus_words)\n",
    "            \n",
    "            target_total = len(target_words)\n",
    "            corpus_total = len(corpus_words)\n",
    "            \n",
    "            if target_total == 0 or corpus_total == 0:\n",
    "                continue\n",
    "            \n",
    "            for word, count in target_freq.items():\n",
    "                target_ratio = count / target_total\n",
    "                corpus_count = corpus_freq.get(word, 0)\n",
    "                \n",
    "                # è°ƒæ•´å‚æ•°ä»¥é€‚åº”åŒè¯­æ–™åº“å¯¹æ¯”\n",
    "                min_corpus_freq = 1 if word_type == \"bigrams\" else 1  # é™ä½Žé—¨æ§›\n",
    "                if corpus_count < min_corpus_freq:\n",
    "                    corpus_ratio = 0.0001\n",
    "                else:\n",
    "                    corpus_ratio = corpus_count / corpus_total\n",
    "                \n",
    "                anomaly_ratio = target_ratio / corpus_ratio if corpus_ratio > 0 else 999\n",
    "                \n",
    "                # æ ¹æ®å¯¹æ¯”ç±»åž‹è°ƒæ•´é˜ˆå€¼\n",
    "                if comparison_type == \"specialist\":\n",
    "                    # ä¸ŽåŒè¡Œå¯¹æ¯”ï¼šæ‰¾ç‰¹è‰²ï¼Œé˜ˆå€¼å¯ä»¥ä½Žä¸€äº›\n",
    "                    min_target_freq = 0.008 if word_type == \"bigrams\" else 0.004\n",
    "                    min_anomaly_ratio = 1.2 if word_type == \"bigrams\" else 1.5\n",
    "                else:  # industry markers\n",
    "                    # ä¸Žå¤–è¡Œå¯¹æ¯”ï¼šæ‰¾è¡Œä¸šæ ‡å¿—ï¼Œé˜ˆå€¼è¦é«˜ä¸€äº›\n",
    "                    min_target_freq = 0.01 if word_type == \"bigrams\" else 0.006\n",
    "                    min_anomaly_ratio = 2.0 if word_type == \"bigrams\" else 3.0\n",
    "                \n",
    "                if (target_ratio >= min_target_freq and \n",
    "                    anomaly_ratio >= min_anomaly_ratio and\n",
    "                    count >= 1):\n",
    "                    \n",
    "                    quality_score = self.calculate_quality_score_enhanced(\n",
    "                        word, job_title, word_type, comparison_type\n",
    "                    )\n",
    "                    \n",
    "                    if quality_score > 0:\n",
    "                        results.append({\n",
    "                            'word': str(word),\n",
    "                            'anomaly_ratio': float(round(anomaly_ratio, 2)),\n",
    "                            'target_frequency': float(round(target_ratio * 100, 3)),\n",
    "                            'corpus_frequency': float(round(corpus_ratio * 100, 4)),\n",
    "                            'target_count': int(count),\n",
    "                            'corpus_count': int(corpus_count),\n",
    "                            'quality_score': float(quality_score),\n",
    "                            'comparison_type': str(comparison_type),\n",
    "                            'word_type': str(word_type)\n",
    "                        })\n",
    "        \n",
    "        # æŽ’åºå¹¶è¿”å›žå‰8ä¸ª\n",
    "        results.sort(key=lambda x: (x['quality_score'], x['anomaly_ratio']), reverse=True)\n",
    "        return results[:8]\n",
    "    \n",
    "    def calculate_quality_score_enhanced(self, word, job_title, word_type, comparison_type):\n",
    "        \"\"\"\n",
    "        å¢žå¼ºç‰ˆè´¨é‡è¯„åˆ†ï¼Œé›†æˆIDFè¿‡æ»¤\n",
    "        \"\"\"\n",
    "        score = 1\n",
    "        \n",
    "        # *** å…³é”®æ”¹è¿›ï¼šåŸºäºŽIDFçš„é€šç”¨è¯é‡ç½š ***\n",
    "        if self.is_generic_word(word):\n",
    "            score -= 3  # é‡ç½šé€šç”¨è¯\n",
    "            print(f\"ðŸš« é€šç”¨è¯æƒ©ç½š: {word} (IDFè¿‡ä½Ž)\")\n",
    "        \n",
    "        # 1. èŒä½æ ‡é¢˜ç›¸å…³æ€§åŠ åˆ†\n",
    "        if job_title and word.lower() in job_title.lower():\n",
    "            score += 2\n",
    "        \n",
    "        # 2. æŠ€æœ¯/æŠ€èƒ½è¯æ±‡åŠ åˆ†\n",
    "        tech_indicators = [\n",
    "            'python', 'java', 'javascript', 'react', 'vue', 'angular', 'node',\n",
    "            'aws', 'azure', 'docker', 'kubernetes', 'git', 'sql', 'nosql',\n",
    "            'machine', 'learning', 'ai', 'data', 'analytics', 'science',\n",
    "            'devops', 'agile', 'scrum', 'api', 'rest', 'graphql',\n",
    "            'testing', 'automation', 'ci/cd', 'jenkins', 'terraform'\n",
    "        ]\n",
    "        \n",
    "        if any(tech in word.lower() for tech in tech_indicators):\n",
    "            score += 2\n",
    "        \n",
    "        # 3. è¡Œä¸šä¸“ä¸šè¯æ±‡åŠ åˆ†  \n",
    "        industry_terms = [\n",
    "            'esg', 'sustainable', 'proptech', 'fintech', 'blockchain', 'cryptocurrency',\n",
    "            'healthcare', 'medical', 'pharmaceutical', 'biotech',\n",
    "            'automotive', 'manufacturing', 'logistics', 'supply',\n",
    "            'consulting', 'strategy', 'framework', 'case study',\n",
    "            'legal', 'compliance', 'regulatory', 'litigation',\n",
    "            'Ã¶ffentlichkeitsarbeit', 'kommunikation', 'leadership communications',\n",
    "            'international', 'global', 'cross border'\n",
    "        ]\n",
    "        \n",
    "        if any(term in word.lower() for term in industry_terms):\n",
    "            score += 2\n",
    "        \n",
    "        # 4. å¯¹æ¯”ç±»åž‹ç‰¹æ®ŠåŠ åˆ†\n",
    "        if comparison_type == \"industry\":\n",
    "            # è¡Œä¸šæ ‡å¿—è¯æ›´æœ‰ä»·å€¼\n",
    "            score += 1\n",
    "        \n",
    "        # 5. Bigramsä¸€èˆ¬æ¯”unigramsæ›´æœ‰ä»·å€¼\n",
    "        if word_type == \"bigrams\":\n",
    "            score += 1\n",
    "        \n",
    "        # 6. åŒ…å«æ•°å­—çš„è¯æ±‡\n",
    "        if re.search(r'\\d', word):\n",
    "            score += 0.5\n",
    "        \n",
    "        # 7. *** æ–°å¢žï¼šæ˜Žç¡®çš„é€šç”¨è¯é»‘åå•é‡ç½š ***\n",
    "        explicit_generic = [\n",
    "            'digital', 'student', 'kreativ', 'innovative', 'modern',\n",
    "            'new', 'current', 'future', 'excellent', 'strong', 'good',\n",
    "            'various', 'different', 'multiple', 'general', 'basic'\n",
    "        ]\n",
    "        \n",
    "        if any(generic in word.lower() for generic in explicit_generic):\n",
    "            score -= 2\n",
    "        \n",
    "        return max(0, score)\n",
    "\n",
    "def run_dual_corpus_detection(csv_file_path, output_json_path, max_jobs=20):\n",
    "    \"\"\"\n",
    "    è¿è¡ŒåŒè¯­æ–™åº“å¼‚å¸¸æ£€æµ‹\n",
    "    \"\"\"\n",
    "    print(\"ðŸš€ å¼€å§‹åŒè¯­æ–™åº“å¯¹æ¯”æ³•å¼‚å¸¸æ£€æµ‹...\")\n",
    "    \n",
    "    # åŠ è½½æ•°æ®\n",
    "    jobs_df = load_and_process_jobs(csv_file_path)\n",
    "    if jobs_df.empty:\n",
    "        return {}\n",
    "    \n",
    "    if len(jobs_df) > max_jobs:\n",
    "        jobs_df = jobs_df.tail(max_jobs)\n",
    "        print(f\"âš ï¸ é™åˆ¶å¤„ç†å‰ {max_jobs} ä¸ªèŒä½ä»¥ä¾¿å¿«é€ŸéªŒè¯\")\n",
    "    \n",
    "    detector = EnhancedJobAnomalyDetector()\n",
    "    \n",
    "    # *** å…³é”®æ­¥éª¤1ï¼šè®¡ç®—å…¨å±€IDFå€¼ ***\n",
    "    detector.calculate_global_idf(jobs_df)\n",
    "    \n",
    "    # *** å…³é”®æ­¥éª¤2ï¼šå¯¹æ‰€æœ‰èŒä½è¿›è¡Œè¡Œä¸šåˆ†ç±» ***\n",
    "    print(\"ðŸ·ï¸ è¿›è¡Œè¡Œä¸šåˆ†ç±»...\")\n",
    "    jobs_df['industry'] = jobs_df.apply(\n",
    "        lambda row: detector.classify_job_industry(\n",
    "            row.get('company_name', ''),\n",
    "            row.get('job_title', ''),\n",
    "            row.get('description', '')\n",
    "        ), axis=1\n",
    "    )\n",
    "    \n",
    "    # æ˜¾ç¤ºè¡Œä¸šåˆ†å¸ƒ\n",
    "    industry_counts = jobs_df['industry'].value_counts()\n",
    "    print(f\"ðŸ“Š è¡Œä¸šåˆ†å¸ƒ: {dict(industry_counts)}\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for idx, row in jobs_df.iterrows():\n",
    "        try:\n",
    "            job_id = row.get('id', f'job_{idx}')\n",
    "            company = row.get('company_name', 'Unknown')\n",
    "            title = row.get('job_title', 'Unknown')\n",
    "            description = row.get('description', '')\n",
    "            industry = row.get('industry', 'general')\n",
    "            \n",
    "            if not description or len(str(description).strip()) < 100:\n",
    "                continue\n",
    "            \n",
    "            # *** å…³é”®æ­¥éª¤3ï¼šæž„å»ºåŒè¯­æ–™åº“ ***\n",
    "            # åŒè¡Œè¯­æ–™åº“ï¼šç›¸åŒè¡Œä¸šçš„å…¶ä»–èŒä½\n",
    "            specialist_corpus = jobs_df[\n",
    "                (jobs_df.index != idx) & \n",
    "                (jobs_df['industry'] == industry)\n",
    "            ]['description'].tolist()\n",
    "            \n",
    "            # å¤–è¡Œè¯­æ–™åº“ï¼šä¸åŒè¡Œä¸šçš„èŒä½\n",
    "            general_corpus = jobs_df[\n",
    "                (jobs_df.index != idx) & \n",
    "                (jobs_df['industry'] != industry)\n",
    "            ]['description'].tolist()\n",
    "            \n",
    "            if len(specialist_corpus) < 2 or len(general_corpus) < 2:\n",
    "                print(f\"âš ï¸ è·³è¿‡ {company}: è¯­æ–™åº“ä¸è¶³ (åŒè¡Œ:{len(specialist_corpus)}, å¤–è¡Œ:{len(general_corpus)})\")\n",
    "                continue\n",
    "            \n",
    "            # *** å…³é”®æ­¥éª¤4ï¼šæ‰§è¡ŒåŒè¯­æ–™åº“å¯¹æ¯” ***\n",
    "            anomalies = detector.detect_anomalies_dual_corpus(\n",
    "                description, \n",
    "                specialist_corpus,\n",
    "                general_corpus,\n",
    "                job_title=title,\n",
    "                company_name=company,\n",
    "                industry=industry\n",
    "            )\n",
    "            \n",
    "            # ç»Ÿè®¡ç»“æžœ\n",
    "            specialist_count = len(anomalies['specialist_anomalies'])\n",
    "            industry_count = len(anomalies['industry_markers'])\n",
    "            total_anomalies = specialist_count + industry_count\n",
    "            \n",
    "            # è®¡ç®—é«˜è´¨é‡å¼‚å¸¸è¯æ•°é‡\n",
    "            high_quality_count = sum(1 for item in \n",
    "                                   anomalies['specialist_anomalies'] + anomalies['industry_markers']\n",
    "                                   if item.get('quality_score', 0) >= 2)\n",
    "            \n",
    "            job_result = {\n",
    "                'job_id': str(job_id),\n",
    "                'company_name': str(company),\n",
    "                'job_title': str(title),\n",
    "                'industry': str(industry),\n",
    "                'description': str(description),\n",
    "                'dual_corpus_anomalies': anomalies,\n",
    "                'quality_metrics': {\n",
    "                    'specialist_anomalies_count': int(specialist_count),\n",
    "                    'industry_markers_count': int(industry_count),\n",
    "                    'total_anomalies': int(total_anomalies),\n",
    "                    'high_quality_anomalies': int(high_quality_count),\n",
    "                    'quality_ratio': float(round(high_quality_count / total_anomalies, 2)) if total_anomalies > 0 else 0.0\n",
    "                },\n",
    "                'dual_corpus_metadata': {\n",
    "                    'industry': str(anomalies['metadata'].get('industry', '')),\n",
    "                    'specialist_corpus_size': int(anomalies['metadata'].get('specialist_corpus_size', 0)),\n",
    "                    'general_corpus_size': int(anomalies['metadata'].get('general_corpus_size', 0)),\n",
    "                    'target_unigrams_count': int(anomalies['metadata'].get('target_unigrams_count', 0)),\n",
    "                    'target_bigrams_count': int(anomalies['metadata'].get('target_bigrams_count', 0)),\n",
    "                    'company_terms_filtered': int(anomalies['metadata'].get('company_terms_filtered', 0))\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            results.append(job_result)\n",
    "            print(f\"âœ… {company} ({industry}) | ç‰¹è‰²è¯:{specialist_count} | è¡Œä¸šè¯:{industry_count} | é«˜è´¨é‡:{high_quality_count}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ å¤„ç†èŒä½ {idx} æ—¶å‡ºé”™: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š\n",
    "    if results:\n",
    "        avg_quality_ratio = np.mean([r['quality_metrics']['quality_ratio'] for r in results])\n",
    "        total_high_quality = sum(r['quality_metrics']['high_quality_anomalies'] for r in results)\n",
    "        \n",
    "        output_data = {\n",
    "            'dual_corpus_summary': {\n",
    "                'version': 'v2.0 - åŒè¯­æ–™åº“å¯¹æ¯”æ³•',\n",
    "                'processing_timestamp': str(pd.Timestamp.now().isoformat()),\n",
    "                'total_jobs_processed': int(len(results)),\n",
    "                'average_quality_ratio': float(round(avg_quality_ratio, 3)),\n",
    "                'total_high_quality_anomalies': int(total_high_quality),\n",
    "                'improvements_implemented': [\n",
    "                    \"åŒè¯­æ–™åº“å¯¹æ¯”æ³• (åŒè¡Œ vs å¤–è¡Œ)\",\n",
    "                    \"åŸºäºŽIDFçš„æ™ºèƒ½é€šç”¨è¯è¿‡æ»¤\",\n",
    "                    \"è¡Œä¸šè‡ªåŠ¨åˆ†ç±»ç³»ç»Ÿ\",\n",
    "                    \"å¢žå¼ºè´¨é‡è¯„åˆ†ç®—æ³•\",\n",
    "                    \"ä¸Šä¸‹æ–‡æ„ŸçŸ¥å¼‚å¸¸æ£€æµ‹\"\n",
    "                ],\n",
    "                'industry_distribution': {str(k): int(v) for k, v in dict(pd.Series([r['industry'] for r in results]).value_counts()).items()}\n",
    "            },\n",
    "            'jobs': results\n",
    "        }\n",
    "        \n",
    "        with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(output_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"\\nðŸŽ‰ åŒè¯­æ–™åº“å¯¹æ¯”æ³•æ£€æµ‹å®Œæˆ!\")\n",
    "        print(f\"ðŸ“Š ç»“æžœç»Ÿè®¡:\")\n",
    "        print(f\"   - å¤„ç†èŒä½æ•°: {len(results)}\")\n",
    "        print(f\"   - å¹³å‡è´¨é‡æ¯”ä¾‹: {avg_quality_ratio:.1%}\")\n",
    "        print(f\"   - é«˜è´¨é‡å¼‚å¸¸è¯æ€»æ•°: {total_high_quality}\")\n",
    "        print(f\"   - è¡Œä¸šåˆ†å¸ƒ: {dict(pd.Series([r['industry'] for r in results]).value_counts())}\")\n",
    "        print(f\"ðŸ“ ç»“æžœå·²ä¿å­˜è‡³: {output_json_path}\")\n",
    "        \n",
    "        return output_data\n",
    "    \n",
    "    else:\n",
    "        print(\"âŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•èŒä½\")\n",
    "        return {}\n",
    "\n",
    "def load_and_process_jobs(csv_file_path):\n",
    "    \"\"\"åŠ è½½å¹¶é¢„å¤„ç†èŒä½æ•°æ®\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        print(f\"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡èŒä½æ•°æ®\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # æŠ€æœ¯èŒä½è¯†åˆ«é€»è¾‘\n",
    "    tech_keywords_high = [\n",
    "        'software', 'developer', 'programming', 'python', 'java', 'javascript',\n",
    "        'react', 'vue', 'angular', 'node.js', 'machine learning', 'data science',\n",
    "        'ai ', 'ml ', 'devops', 'cloud', 'aws', 'azure', 'docker', 'kubernetes'\n",
    "    ]\n",
    "    \n",
    "    tech_keywords_medium = [\n",
    "        'technical', 'technology', 'it ', 'computer', 'digital', 'web',\n",
    "        'mobile', 'app', 'api', 'database', 'sql', 'analytics', 'algorithm'\n",
    "    ]\n",
    "    \n",
    "    def calculate_tech_score(row):\n",
    "        title = str(row.get('job_title', '')).lower()\n",
    "        desc = str(row.get('description', '')).lower()\n",
    "        combined = title + ' ' + desc\n",
    "        \n",
    "        high_score = sum(2 for keyword in tech_keywords_high if keyword in combined)\n",
    "        medium_score = sum(1 for keyword in tech_keywords_medium if keyword in combined)\n",
    "        \n",
    "        return high_score + medium_score\n",
    "    \n",
    "    df['tech_score'] = df.apply(calculate_tech_score, axis=1)\n",
    "    tech_jobs = df[df['tech_score'] >= 2].copy()\n",
    "    \n",
    "    print(f\"âœ… ç­›é€‰å‡º {len(tech_jobs)} ä¸ªæŠ€æœ¯ç›¸å…³èŒä½\")\n",
    "    return tech_jobs\n",
    "\n",
    "def analyze_detection_quality(results, known_important_terms=None):\n",
    "    \"\"\"\n",
    "    åˆ†æžæ£€æµ‹è´¨é‡ï¼Œæ¨¡æ‹ŸHRè¯„ä¼°\n",
    "    \"\"\"\n",
    "    if not results or not results.get('jobs'):\n",
    "        return {}\n",
    "    \n",
    "    print(\"\\nðŸ” è´¨é‡åˆ†æžæŠ¥å‘Š:\")\n",
    "    \n",
    "    quality_analysis = {\n",
    "        'jobs_analyzed': len(results['jobs']),\n",
    "        'quality_breakdown': {},\n",
    "        'common_patterns': {\n",
    "            'high_quality_terms': [],\n",
    "            'questionable_terms': [],\n",
    "            'missed_opportunities': []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    all_specialist_terms = []\n",
    "    all_industry_terms = []\n",
    "    \n",
    "    for job in results['jobs']:\n",
    "        company = job['company_name']\n",
    "        industry = job['industry'] \n",
    "        \n",
    "        specialist_anomalies = job['dual_corpus_anomalies']['specialist_anomalies']\n",
    "        industry_markers = job['dual_corpus_anomalies']['industry_markers']\n",
    "        \n",
    "        high_quality_specialist = [item for item in specialist_anomalies if item['quality_score'] >= 2]\n",
    "        high_quality_industry = [item for item in industry_markers if item['quality_score'] >= 2]\n",
    "        \n",
    "        all_specialist_terms.extend([item['word'] for item in high_quality_specialist])\n",
    "        all_industry_terms.extend([item['word'] for item in high_quality_industry])\n",
    "        \n",
    "        print(f\"\\nðŸ“‹ {company} ({industry}):\")\n",
    "        print(f\"  ðŸŽ¯ ç‰¹è‰²è¯æ±‡: {[item['word'] for item in high_quality_specialist[:3]]}\")\n",
    "        print(f\"  ðŸ·ï¸ è¡Œä¸šæ ‡å¿—: {[item['word'] for item in high_quality_industry[:3]]}\")\n",
    "    \n",
    "    # ç»Ÿè®¡æœ€å¸¸è§çš„é«˜è´¨é‡æœ¯è¯­\n",
    "    specialist_counter = Counter(all_specialist_terms)\n",
    "    industry_counter = Counter(all_industry_terms)\n",
    "    \n",
    "    quality_analysis['common_patterns']['high_quality_specialist'] = specialist_counter.most_common(10)\n",
    "    quality_analysis['common_patterns']['high_quality_industry'] = industry_counter.most_common(10)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š æœ€å¸¸æ£€æµ‹åˆ°çš„ç‰¹è‰²æœ¯è¯­: {specialist_counter.most_common(5)}\")\n",
    "    print(f\"ðŸ“Š æœ€å¸¸æ£€æµ‹åˆ°çš„è¡Œä¸šæœ¯è¯­: {industry_counter.most_common(5)}\")\n",
    "    \n",
    "    return quality_analysis\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•å‡½æ•°\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file = \"/Users/wenjiaqi/Downloads/job_analyzer_service/sample_data/job_listings_rows.csv\"  # è¯·æ›¿æ¢ä¸ºå®žé™…è·¯å¾„\n",
    "    output_file = \"dual_corpus_enhanced_results.json\"\n",
    "    \n",
    "    # è¿è¡ŒåŒè¯­æ–™åº“æ£€æµ‹\n",
    "    results = run_dual_corpus_detection(csv_file, output_file, max_jobs=10)\n",
    "    \n",
    "    # è´¨é‡åˆ†æž\n",
    "    if results:\n",
    "        quality_report = analyze_detection_quality(results)\n",
    "        \n",
    "        # æ˜¾ç¤ºæ”¹è¿›æ•ˆæžœé¢„è§ˆ\n",
    "        print(f\"\\n=== åŒè¯­æ–™åº“å¯¹æ¯”æ³•æ•ˆæžœé¢„è§ˆ ===\")\n",
    "        sample = results['jobs'][0] if results['jobs'] else None\n",
    "        \n",
    "        if sample:\n",
    "            print(f\"ðŸ¢ å…¬å¸: {sample['company_name']}\")\n",
    "            print(f\"ðŸ“‹ èŒä½: {sample['job_title']}\")\n",
    "            print(f\"ðŸ·ï¸ è¡Œä¸š: {sample['industry']}\")\n",
    "            print(f\"ðŸ“Š è´¨é‡æŒ‡æ ‡: {sample['quality_metrics']}\")\n",
    "            \n",
    "            specialist_anomalies = sample['dual_corpus_anomalies']['specialist_anomalies']\n",
    "            industry_markers = sample['dual_corpus_anomalies']['industry_markers']\n",
    "            \n",
    "            if specialist_anomalies:\n",
    "                print(f\"\\nðŸŽ¯ ä¸ŽåŒè¡Œå¯¹æ¯”å‘çŽ°çš„ç‰¹è‰²è¯æ±‡:\")\n",
    "                for item in specialist_anomalies[:3]:\n",
    "                    print(f\"  â€¢ {item['word']} (å¼‚å¸¸æ¯”ä¾‹: {item['anomaly_ratio']}x, è´¨é‡åˆ†: {item['quality_score']})\")\n",
    "            \n",
    "            if industry_markers:\n",
    "                print(f\"\\nðŸ·ï¸ ä¸Žå¤–è¡Œå¯¹æ¯”å‘çŽ°çš„è¡Œä¸šæ ‡å¿—:\")\n",
    "                for item in industry_markers[:3]:\n",
    "                    print(f\"  â€¢ {item['word']} (å¼‚å¸¸æ¯”ä¾‹: {item['anomaly_ratio']}x, è´¨é‡åˆ†: {item['quality_score']})\")\n",
    "        \n",
    "        print(f\"\\nâœ… åŒè¯­æ–™åº“å¯¹æ¯”æ³•å®žçŽ°å®Œæˆ!\")\n",
    "        print(f\"ðŸš€ æ ¸å¿ƒæ”¹è¿›:\")\n",
    "        print(f\"   âœ“ åŒè¡Œå¯¹æ¯”æ‰¾ç‰¹è‰² (specialist_anomalies)\")\n",
    "        print(f\"   âœ“ å¤–è¡Œå¯¹æ¯”æ‰¾è¡Œä¸šåŸºå›  (industry_markers)\")\n",
    "        print(f\"   âœ“ åŸºäºŽIDFçš„æ™ºèƒ½é€šç”¨è¯è¿‡æ»¤\")\n",
    "        print(f\"   âœ“ è¡Œä¸šè‡ªåŠ¨åˆ†ç±»ç³»ç»Ÿ\")\n",
    "        print(f\"   âœ“ ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è´¨é‡è¯„åˆ†\")\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ ä¸‹ä¸€æ­¥å»ºè®®:\")\n",
    "    print(\"1. åœ¨10ä¸ªHRè¯„ä¼°çš„èŒä½ä¸Šæµ‹è¯•æ–°ç®—æ³•\")\n",
    "    print(\"2. å¯¹æ¯”æ–°æ—§ç»“æžœï¼ŒéªŒè¯'ESG'ã€'international'ç­‰å…³é”®è¯çš„æ£€æµ‹æ•ˆæžœ\")\n",
    "    print(\"3. è°ƒæ•´IDFé˜ˆå€¼å’Œè´¨é‡è¯„åˆ†æƒé‡\")\n",
    "    print(\"4. å‡†å¤‡é«˜è´¨é‡ç»“æžœè¾“å…¥åˆ°LLMè¿›è¡Œè¯­ä¹‰åˆ†æž\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
